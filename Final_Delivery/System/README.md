# Chocolate Sales Prediction - R-Powered ML Pipeline

## ğŸ¯ Project Overview

3-layer machine learning pipeline for chocolate sales prediction:
- **Layer 1 (Python)**: Data processing and statistical analysis
- **Layer 2 (R)**: Model training and selection
- **Layer 3 (Python API + Web)**: Predictions and visualization

## ğŸš€ Quick Start

### Run Complete Pipeline

```bash
python run_pipeline.py
```

This will:
1. Process raw data (`main.py`)
2. Train and compare models in R
3. Generate visualizations
4. Save the best model

### Start Web Interface

```bash
python "Presentation Layer/api.py"
```

Then open: **http://localhost:8000**

## ğŸ“ Project Structure

```
WORKSHOP4/
â”œâ”€â”€ IN/                          # Input data
â”œâ”€â”€ OUT/                         # Outputs
â”‚   â”œâ”€â”€ processed_data.csv      # Processed dataset
â”‚   â”œâ”€â”€ *.png                   # Visualizations
â”‚   â”œâ”€â”€ model_comparison_results_R.json
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ best_model_R.rds    # Trained R model
â”œâ”€â”€ Data Processing Layer/
â”‚   â”œâ”€â”€ main.py                 # Data processing
â”‚   â””â”€â”€ DataIngestionModule.py
â”œâ”€â”€ Training Layer/
â”‚   â””â”€â”€ compare_models.R        # R model training
â”œâ”€â”€ Presentation Layer/
â”‚   â”œâ”€â”€ api.py                  # FastAPI server
â”‚   â”œâ”€â”€ predict.R               # R prediction script
â”‚   â””â”€â”€ index.html              # Web dashboard
â”œâ”€â”€ run_pipeline.py             # Master script
â””â”€â”€ docker-compose.yml          # Docker deployment
```

## ğŸ”¬ What Each Layer Does

### Layer 1: Data Processing (Python)
- Loads raw data from `IN/`
- Statistical analysis and feature engineering
- Generates visualizations (heatmaps, boxplots, etc.)
- Outputs: `OUT/processed_data.csv` + PNG files

### Layer 2: Training (R)
- Compares 4 models: Linear, Random Forest, GBM, XGBoost
- Cross-validation with 5 folds
- Selects best model based on MAE
- Saves model to `OUT/models/best_model_R.rds`

### Layer 3: Presentation (Python + R)
- FastAPI serves web interface
- Calls R for predictions via `predict.R`
- Web dashboard shows visualizations and results
- Upload CSV to get predictions

## ğŸ³ Docker Deployment

```bash
# Build and run
docker-compose up --build

# Access
http://localhost:8000
```

## ğŸ“Š Model Results

The R training script compares:
1. Linear Regression (baseline)
2. Random Forest
3. Gradient Boosting (GBM)
4. XGBoost â­ (typically wins)

Results saved to: `OUT/model_comparison_results_R.json`

## ğŸ”§ Manual Steps

If you want to run each step individually:

```bash
# Step 1: Process data
python main.py

# Step 2: Train models in R
Rscript "Training Layer/compare_models.R"

# Step 3: Start API
python "Presentation Layer/api.py"
```

## ğŸ“ API Endpoints

- `GET /` - Web dashboard
- `GET /health` - API health check
- `POST /predict` - Get predictions (JSON)
- `POST /predict/csv` - Download predictions as CSV

## ğŸ› ï¸ Technologies

- **Python**: pandas, numpy, scikit-learn, matplotlib, seaborn, FastAPI
- **R**: caret, xgboost, randomForest, gbm, jsonlite
- **Web**: HTML, CSS, JavaScript
- **Deployment**: Docker

## ğŸ“Œ Notes

- All comments in English (student-friendly style)
- R is the primary training engine
- Python handles data prep and API
- Model comparison ensures best algorithm selection

---

**Status**: âœ… Production-ready R-powered ML pipeline